using Discord;
using Discord.Interactions;
using LLMDiscordBot.Services;
using LLMDiscordBot.Data;
using LLMDiscordBot.Models;
using Microsoft.SemanticKernel.ChatCompletion;
using Serilog;

namespace LLMDiscordBot.Commands;

/// <summary>
/// Chat commands for interacting with the LLM
/// </summary>
public class ChatCommands(
    LLMService llmService,
    TokenControlService tokenControl,
    IRepository repository,
    UserRequestQueueService requestQueue,
    ILogger logger) : InteractionModuleBase<SocketInteractionContext>
{

    [SlashCommand("chat", "èˆ‡ LLM èŠå¤©")]
    public async Task ChatAsync(
        [Summary("message", "æ‚¨æƒ³èªªçš„è©±")]
        string message)
    {
        // Defer response as LLM might take time
        await DeferAsync();

        var userId = Context.User.Id;
        var channelId = Context.Channel.Id;

        // Acquire user-specific lock to serialize requests and prevent race conditions
        using var userLock = await requestQueue.AcquireUserLockAsync(userId);

        try
        {
            logger.Information("User {Username} ({UserId}) sent chat message in channel {ChannelId}",
                Context.User.Username, userId, channelId);

            // Estimate tokens needed for the message
            var estimatedTokens = llmService.EstimateTokenCount(message) + 500; // Add buffer for response

            // Check token limit
            var (allowed, used, limit) = await tokenControl.CheckTokenLimitAsync(userId, estimatedTokens);
            if (!allowed)
            {
                await FollowupAsync(
                    embed: new EmbedBuilder()
                        .WithColor(Color.Red)
                        .WithTitle("âŒ Token é¡åº¦ä¸è¶³")
                        .WithDescription($"æ‚¨ä»Šå¤©çš„ Token é¡åº¦å·²ç”¨å®Œã€‚\n\n" +
                                       $"å·²ä½¿ç”¨: {used:N0} / {limit:N0}")
                        .WithFooter("é¡åº¦å°‡åœ¨æ¯æ—¥ 00:00 UTC é‡ç½®")
                        .Build(),
                    ephemeral: true);
                return;
            }

            // Build chat history
            var chatHistory = await llmService.BuildChatHistoryAsync(userId, channelId, message);

            // Stream LLM response with real-time updates
            var responseBuilder = new System.Text.StringBuilder();
            var lastUpdateTime = DateTime.UtcNow;
            int? promptTokens = null;
            int? completionTokens = null;
            var hasContent = false;

            await foreach (var (content, pTokens, cTokens) in llmService.GetChatCompletionStreamingAsync(chatHistory))
            {
                if (!string.IsNullOrEmpty(content))
                {
                    responseBuilder.Append(content);
                    hasContent = true;

                    // Update token counts if available
                    if (pTokens.HasValue) promptTokens = pTokens.Value;
                    if (cTokens.HasValue) completionTokens = cTokens.Value;

                    // Update Discord message every 1 second
                    var now = DateTime.UtcNow;
                    if ((now - lastUpdateTime).TotalSeconds >= 1.0)
                    {
                        lastUpdateTime = now;
                        var currentContent = responseBuilder.ToString();

                        // Truncate if too long for streaming display (Discord embed limit)
                        var displayContent = currentContent.Length > 1900 
                            ? currentContent.Substring(0, 1900) + "..." 
                            : currentContent;

                        var streamingEmbed = new EmbedBuilder()
                            .WithColor(Color.Blue)
                            .WithAuthor(Context.User.Username, Context.User.GetAvatarUrl())
                            .WithTitle($"ğŸ’¬ {(message.Length > 100 ? message.Substring(0, 100) + "..." : message)}")
                            .WithDescription(displayContent)
                            .WithFooter("æ­£åœ¨ç”Ÿæˆå›æ‡‰...")
                            .Build();

                        try
                        {
                            await ModifyOriginalResponseAsync(msg =>
                            {
                                msg.Content = null;
                                msg.Embed = streamingEmbed;
                            });
                        }
                        catch (Exception ex)
                        {
                            // Log but don't stop streaming if update fails
                            logger.Warning(ex, "Failed to update streaming message");
                        }
                    }
                }
            }

            var response = responseBuilder.ToString();

            // If no content was received, handle error
            if (!hasContent || string.IsNullOrEmpty(response))
            {
                logger.Warning("No content received from LLM streaming");
                response = "æŠ±æ­‰ï¼Œç„¡æ³•ç”Ÿæˆå›æ‡‰ã€‚è«‹ç¨å¾Œå†è©¦ã€‚";
                // Use accurate calculation if no token data available
                promptTokens = llmService.CalculateTokenCount(message);
                completionTokens = 0;
            }
            else
            {
                // Calculate tokens accurately if API didn't return usage info
                if (!promptTokens.HasValue)
                {
                    promptTokens = llmService.CalculateTokenCount(message);
                    logger.Information("Calculated prompt tokens (API didn't provide): {Tokens}", promptTokens.Value);
                }

                if (!completionTokens.HasValue)
                {
                    completionTokens = llmService.CalculateTokenCount(response);
                    logger.Information("Calculated completion tokens (API didn't provide): {Tokens}", completionTokens.Value);
                }
            }

            var totalTokens = (promptTokens ?? 0) + (completionTokens ?? 0);

            // Record token usage
            await tokenControl.RecordTokenUsageAsync(userId, totalTokens);

            // Save chat history
            await repository.AddChatHistoryAsync(new Models.ChatHistory
            {
                UserId = userId,
                ChannelId = channelId,
                Role = "user",
                Content = message,
                TokenCount = promptTokens ?? 0,
                Timestamp = DateTime.UtcNow
            });

            await repository.AddChatHistoryAsync(new Models.ChatHistory
            {
                UserId = userId,
                ChannelId = channelId,
                Role = "assistant",
                Content = response,
                TokenCount = completionTokens ?? 0,
                Timestamp = DateTime.UtcNow
            });

            // Update final message with complete response
            // Split response if too long (Discord limit is 2000 characters per message)
            if (response.Length <= 1900)
            {
                var embed = new EmbedBuilder()
                    .WithColor(Color.Blue)
                    .WithAuthor(Context.User.Username, Context.User.GetAvatarUrl())
                    .WithTitle($"ğŸ’¬ {(message.Length > 100 ? string.Concat(message.AsSpan(0, 100), "...") : message)}")
                    .WithDescription(response)
                    .WithFooter($"ä½¿ç”¨ {totalTokens:N0} tokens | ä»Šæ—¥å·²ä½¿ç”¨ {used + totalTokens:N0} / {limit:N0}")
                    .Build();

                await ModifyOriginalResponseAsync(msg =>
                {
                    msg.Content = null; // Clear the "thinking" text
                    msg.Embed = embed;
                });
            }
            else
            {
                // Split into multiple messages
                var chunks = SplitMessage(response, 1900);
                for (int i = 0; i < chunks.Count; i++)
                {
                    var embedBuilder = new EmbedBuilder()
                        .WithColor(Color.Blue)
                        .WithDescription(chunks[i]);

                    // Add user info and question only to first chunk
                    if (i == 0)
                    {
                        embedBuilder
                            .WithAuthor(Context.User.Username, Context.User.GetAvatarUrl())
                            .WithTitle($"ğŸ’¬ {(message.Length > 100 ? message.Substring(0, 100) + "..." : message)}");
                    }

                    if (i == chunks.Count - 1)
                    {
                        embedBuilder.WithFooter($"ä½¿ç”¨ {totalTokens:N0} tokens | ä»Šæ—¥å·²ä½¿ç”¨ {used + totalTokens:N0} / {limit:N0}");
                    }

                    // First chunk updates the original deferred message, subsequent chunks use followup
                    if (i == 0)
                    {
                        await ModifyOriginalResponseAsync(msg =>
                        {
                            msg.Content = null; // Clear the "thinking" text
                            msg.Embed = embedBuilder.Build();
                        });
                    }
                    else
                    {
                        await FollowupAsync(embed: embedBuilder.Build());
                    }
                }
            }

            logger.Information("Chat response sent to user {UserId}. Tokens: {Tokens}", userId, totalTokens);
        }
        catch (Exception ex)
        {
            logger.Error(ex, "Error in chat command");
            await FollowupAsync(
                embed: new EmbedBuilder()
                    .WithColor(Color.Red)
                    .WithTitle("âŒ éŒ¯èª¤")
                    .WithDescription("è™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
                    .Build(),
                ephemeral: true);
        }
    }

    [SlashCommand("clearchat", "æ¸…é™¤æ‚¨åœ¨æ­¤é »é“çš„èŠå¤©è¨˜éŒ„")]
    public async Task ClearChatAsync()
    {
        try
        {
            var userId = Context.User.Id;
            var channelId = Context.Channel.Id;

            await repository.ClearChatHistoryAsync(userId, channelId);

            await RespondAsync(
                embed: new EmbedBuilder()
                    .WithColor(Color.Green)
                    .WithTitle("âœ… èŠå¤©è¨˜éŒ„å·²æ¸…é™¤")
                    .WithDescription("æ‚¨åœ¨æ­¤é »é“çš„èŠå¤©è¨˜éŒ„å·²è¢«æ¸…é™¤ã€‚")
                    .Build(),
                ephemeral: true);

            logger.Information("User {UserId} cleared chat history in channel {ChannelId}", userId, channelId);
        }
        catch (Exception ex)
        {
            logger.Error(ex, "Error clearing chat history");
            await RespondAsync("ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚", ephemeral: true);
        }
    }

    private List<string> SplitMessage(string message, int maxLength)
    {
        var chunks = new List<string>();
        var lines = message.Split('\n');
        var currentChunk = "";

        foreach (var line in lines)
        {
            if (currentChunk.Length + line.Length + 1 > maxLength)
            {
                if (!string.IsNullOrEmpty(currentChunk))
                {
                    chunks.Add(currentChunk);
                    currentChunk = "";
                }

                // If a single line is too long, split it
                if (line.Length > maxLength)
                {
                    for (int i = 0; i < line.Length; i += maxLength)
                    {
                        chunks.Add(line.Substring(i, Math.Min(maxLength, line.Length - i)));
                    }
                }
                else
                {
                    currentChunk = line + "\n";
                }
            }
            else
            {
                currentChunk += line + "\n";
            }
        }

        if (!string.IsNullOrEmpty(currentChunk))
        {
            chunks.Add(currentChunk);
        }

        return chunks;
    }
}

